{
  "id": "dcf2fcac-6293-4a86-b30b-f63e420177f2",
  "revision": 0,
  "last_node_id": 105,
  "last_link_id": 108,
  "nodes": [
    {
      "id": 78,
      "type": "Note",
      "pos": [
        18,
        -46
      ],
      "size": [
        210,
        88
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "You can write prompt here\n（你可以在此填写提示词）"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 73,
      "type": "FunTextBox",
      "pos": [
        250,
        160
      ],
      "size": [
        383.7149963378906,
        183.83506774902344
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "prompt",
          "type": "STRING_PROMPT",
          "slot_index": 0,
          "links": [
            101
          ]
        }
      ],
      "title": "Negtive Prompt（反向提示词）",
      "properties": {
        "Node name for S&R": "FunTextBox"
      },
      "widgets_values": [
        "色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走"
      ]
    },
    {
      "id": 80,
      "type": "Note",
      "pos": [
        -92,
        -294
      ],
      "size": [
        351.1499938964844,
        130.12660217285156
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "When using the 1.3B model, you can set GPU_memory_mode to model_cpu_offload for faster generation. When using the 20B model, you can use sequential_cpu_offload to save GPU memory during generation.\n（在使用1.3B模型时，可以设置GPU_memory_mode为model_cpu_offload进行更快速度的生成，在使用20B模型时，可以使用sequential_cpu_offload节省显存，进行生成。）"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 91,
      "type": "LoadQwenImageTextEncoderModel",
      "pos": [
        283.53765869140625,
        -280.6837463378906
      ],
      "size": [
        407.4130859375,
        102
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "text_encoder",
          "type": "TextEncoderModel",
          "links": [
            80
          ]
        },
        {
          "name": "tokenizer",
          "type": "Tokenizer",
          "links": [
            81
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "LoadQwenImageTextEncoderModel"
      },
      "widgets_values": [
        "qwen_2.5_vl_7b_fp8_scaled.safetensors",
        "bf16"
      ]
    },
    {
      "id": 92,
      "type": "LoadQwenImageTransformerModel",
      "pos": [
        275.9798278808594,
        -465.2391052246094
      ],
      "size": [
        416.3677673339844,
        106.13789367675781
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "transformer",
          "type": "TransformerModel",
          "links": [
            87
          ]
        },
        {
          "name": "model_name",
          "type": "STRING",
          "links": [
            82
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "LoadQwenImageTransformerModel"
      },
      "widgets_values": [
        "qwen_image_2512_fp8_e4m3fn.safetensors",
        false,
        "bf16"
      ]
    },
    {
      "id": 98,
      "type": "LoadQwenImageControlNetInModel",
      "pos": [
        753.1154601481974,
        -466.61377999428464
      ],
      "size": [
        543.8293619798113,
        82
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "transformer",
          "type": "TransformerModel",
          "link": 87
        }
      ],
      "outputs": [
        {
          "name": "transformer",
          "type": "TransformerModel",
          "links": [
            88
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "LoadQwenImageControlNetInModel"
      },
      "widgets_values": [
        "qwenimage/qwenimage_control.yaml",
        "Qwen-Image-2512-Fun-Controlnet-Union.safetensors"
      ]
    },
    {
      "id": 88,
      "type": "PreviewImage",
      "pos": [
        1070.207763671875,
        -73.63389587402344
      ],
      "size": [
        366.56134033203125,
        415.4429626464844
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 103
        }
      ],
      "outputs": [],
      "properties": {
        "Node name for S&R": "PreviewImage"
      },
      "widgets_values": []
    },
    {
      "id": 93,
      "type": "LoadQwenImageVAEModel",
      "pos": [
        1133.7959245028942,
        -257.8118537612475
      ],
      "size": [
        377.8583984375,
        84.69844055175781
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "vae",
          "type": "VAEModel",
          "links": [
            79
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "LoadQwenImageVAEModel"
      },
      "widgets_values": [
        "qwen_image_vae.safetensors",
        "bf16"
      ]
    },
    {
      "id": 96,
      "type": "CombineQwenImagePipeline",
      "pos": [
        754.4458784421624,
        -332.72602712957854
      ],
      "size": [
        342.5804748535156,
        162
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "transformer",
          "type": "TransformerModel",
          "link": 88
        },
        {
          "name": "vae",
          "type": "VAEModel",
          "link": 79
        },
        {
          "name": "text_encoder",
          "type": "TextEncoderModel",
          "link": 80
        },
        {
          "name": "tokenizer",
          "type": "Tokenizer",
          "link": 81
        },
        {
          "name": "processor",
          "shape": 7,
          "type": "Processor",
          "link": null
        },
        {
          "name": "model_name",
          "type": "STRING",
          "widget": {
            "name": "model_name"
          },
          "link": 82
        }
      ],
      "outputs": [
        {
          "name": "funmodels",
          "type": "FunModels",
          "links": [
            99
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CombineQwenImagePipeline"
      },
      "widgets_values": [
        "",
        "model_group_offload"
      ]
    },
    {
      "id": 75,
      "type": "FunTextBox",
      "pos": [
        250,
        -50
      ],
      "size": [
        383.54010009765625,
        156.71620178222656
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "prompt",
          "type": "STRING_PROMPT",
          "slot_index": 0,
          "links": [
            100
          ]
        }
      ],
      "title": "Positive Prompt（正向提示词）",
      "properties": {
        "Node name for S&R": "FunTextBox"
      },
      "widgets_values": [
        "A photo of Sakura, a 17-year-old high school student from Japan, captured in a candid, high-fidelity cinematic moment on a rainy evening. She is squatting low on the rain-slicked asphalt of an urban sidewalk, holding a transparent vinyl umbrella with a white handle resting over her shoulder in one hand, her other hand resting on her knee. The clear plastic canopy is streaked with rivulets of water and beaded with droplets that catch the ambient city light. A profound, silent interaction defines the scene: Sakura is looking directly downward, her expression gentle and focused, locking eyes with a small black cat sitting on the wet ground in front of her.\\n\\nSakura has long, lustrous black hair styled in a precise hime cut with blunt bangs across her forehead and sidelocks framing her cheeks, damp strands clinging subtly to her jacket, with a single red ribbon tied on the left side. Her visible pores on her nose, and a soft sheen of moisture on her cheeks. She wears a dark navy sailor-style school uniform (seifuku) featuring a white collar with red linear detailing and a bright red necktie loosely knotted at the chest; a simple black choker encircles her neck. The uniform jacket has oversized sleeves. Her lower body features a short, dark pleated miniskirt that fans slightly over clean white ankle socks that provide a stark contrast to the wet asphalt, ending in dark leather loafers that gleam with moisture.\\n\\nThe black cat sits upright in a shallow puddle, its short fur slicked by the rain, tilting its head back to stare intently up into Sakura's face, establishing a clear line of sight. The background is anchored by a large, illuminated red vending machine standing against the darkness, its cool bluish-white interior light spilling onto Sakura's profile and the umbrella. The ground reflects the red chassis and the neon streetlights in distorted patches on the wet pavement. Additional cool rain streaks fall through the frame, some caught in sharp focus and others blurred into vertical lines against the background lights. The scene is rendered with a wide-aperture lens creating a shallow depth of field, keeping the girl and cat in sharp focus while softening the background into gentle bokeh, with the texture of fine-grain 35mm film stock."
      ]
    },
    {
      "id": 104,
      "type": "MaskToImage",
      "pos": [
        665.9127469276586,
        458.2047154396486
      ],
      "size": [
        140,
        26
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "mask",
          "type": "MASK",
          "link": 105
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            104,
            106
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "MaskToImage"
      },
      "widgets_values": []
    },
    {
      "id": 105,
      "type": "LoadImage",
      "pos": [
        360.8304806417201,
        460.85158208210487
      ],
      "size": [
        270,
        314.00000000000006
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            108
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": [
            105
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage",
        "image": "clipspace/clipspace-painted-masked-1766731857414.png [input]"
      },
      "widgets_values": [
        "clipspace/clipspace-painted-masked-1766731857414.png [input]",
        "image"
      ]
    },
    {
      "id": 103,
      "type": "PreviewImage",
      "pos": [
        839.792105488772,
        453.4970846240923
      ],
      "size": [
        366.56134033203125,
        415.4429626464844
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 104
        }
      ],
      "outputs": [],
      "properties": {
        "Node name for S&R": "PreviewImage"
      },
      "widgets_values": []
    },
    {
      "id": 102,
      "type": "QwenImageControlSampler",
      "pos": [
        743.3433452139876,
        -72.05094395600588
      ],
      "size": [
        289.5494140625,
        470
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "funmodels",
          "type": "FunModels",
          "link": 99
        },
        {
          "name": "prompt",
          "type": "STRING_PROMPT",
          "link": 100
        },
        {
          "name": "negative_prompt",
          "type": "STRING_PROMPT",
          "link": 101
        },
        {
          "name": "control_image",
          "shape": 7,
          "type": "IMAGE",
          "link": null
        },
        {
          "name": "inpaint_image",
          "shape": 7,
          "type": "IMAGE",
          "link": 108
        },
        {
          "name": "mask_image",
          "shape": 7,
          "type": "IMAGE",
          "link": 106
        }
      ],
      "outputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "links": [
            103
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "QwenImageControlSampler"
      },
      "widgets_values": [
        1184,
        1568,
        284014972131965,
        "randomize",
        40,
        4,
        "Flow",
        3,
        0.25,
        true,
        5,
        true,
        0,
        0.8
      ]
    }
  ],
  "links": [
    [
      79,
      93,
      0,
      96,
      1,
      "VAEModel"
    ],
    [
      80,
      91,
      0,
      96,
      2,
      "TextEncoderModel"
    ],
    [
      81,
      91,
      1,
      96,
      3,
      "Tokenizer"
    ],
    [
      82,
      92,
      1,
      96,
      5,
      "STRING"
    ],
    [
      87,
      92,
      0,
      98,
      0,
      "TransformerModel"
    ],
    [
      88,
      98,
      0,
      96,
      0,
      "TransformerModel"
    ],
    [
      99,
      96,
      0,
      102,
      0,
      "FunModels"
    ],
    [
      100,
      75,
      0,
      102,
      1,
      "STRING_PROMPT"
    ],
    [
      101,
      73,
      0,
      102,
      2,
      "STRING_PROMPT"
    ],
    [
      103,
      102,
      0,
      88,
      0,
      "IMAGE"
    ],
    [
      104,
      104,
      0,
      103,
      0,
      "IMAGE"
    ],
    [
      105,
      105,
      1,
      104,
      0,
      "MASK"
    ],
    [
      106,
      104,
      0,
      102,
      5,
      "IMAGE"
    ],
    [
      108,
      105,
      0,
      102,
      4,
      "IMAGE"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Load Model",
      "bounding": [
        227.96267700195312,
        -546.4359741210938,
        1350.7047455077704,
        391.2301145558972
      ],
      "color": "#b06634",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Prompts",
      "bounding": [
        218,
        -127,
        450,
        483
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.7034334668812453,
      "offset": [
        333.2705669168081,
        543.6154736676693
      ]
    },
    "frontendVersion": "1.36.14",
    "workspace_info": {
      "id": "776b62b4-bd17-4ed3-9923-b7aad000b1ea"
    },
    "node_versions": {
      "CogVideoX-Fun": "ac114cc14285c8e0073a3e08e27525263d1264a7",
      "comfy-core": "0.9.2"
    },
    "workflowRendererVersion": "LG"
  },
  "version": 0.4
}